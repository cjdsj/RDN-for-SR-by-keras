{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RDN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY9xUOaOl6up"
      },
      "source": [
        "1.获取参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FqzFYMIl3kW"
      },
      "source": [
        "scale = 3  # LR缩小的比率\r\n",
        "size = 32  # 输入大小，输出的size还要乘以scale\r\n",
        "aug_num = 0  # 数据扩充的数量\r\n",
        "num_G = 32  # RDN中每个卷积层卷积核的数量\r\n",
        "Imgflag = 2  # 图片读取方式:0为RGB图，1为灰度图，2为亮度图中Y图层\r\n",
        "if Imgflag == 0:\r\n",
        "  channels = 3\r\n",
        "else:\r\n",
        "  channels = 1\r\n",
        "\r\n",
        "Imglist = ['RGB', 'GRAY', 'YCrCb']\r\n",
        "print('Have got parameters, for ' + Imglist[Imgflag] + ' images.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h3a9H_El9oy"
      },
      "source": [
        "2.制作训练集和验证集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHpyQN3Ml_r7"
      },
      "source": [
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "\r\n",
        "def delcrust(HR_img, scale, Imgflag, Rflag=0):\r\n",
        "  HR_size = HR_img.shape\r\n",
        "  rem0 = HR_size[0]%scale\r\n",
        "  rem1 = HR_size[1]%scale\r\n",
        "  if Imgflag == 0:\r\n",
        "    HR_img = HR_img[:HR_size[0]-rem0, :HR_size[1]-rem1, :]  # 裁掉无法被scale整除的边缘，即为处理后的HR\r\n",
        "  else:\r\n",
        "    HR_img = HR_img[:HR_size[0]-rem0, :HR_size[1]-rem1]  # 裁掉无法被scale整除的边缘，即为处理后的HR\r\n",
        "  ''' Rflag=0，生成HR；Rflag=1，生成LR；Rflag=2，生成ILR。默认生成HR '''\r\n",
        "  if Rflag == 0:\r\n",
        "    return HR_img\r\n",
        "  if Rflag == 1 or Rflag == 2:\r\n",
        "    HR_size = HR_img.shape\r\n",
        "    HR_size = (HR_size[1], HR_size[0])\r\n",
        "    LR_size = (int(HR_size[0]/scale), int(HR_size[1]/scale))\r\n",
        "    LR_img = cv2.resize(HR_img, LR_size, interpolation = cv2.INTER_LINEAR)  # 边长缩小scale倍\r\n",
        "    if Rflag == 1:\r\n",
        "      return LR_img\r\n",
        "    else:\r\n",
        "      ILR_img = cv2.resize(LR_img, HR_size, interpolation = cv2.INTER_LINEAR)  # 再插值恢复成HR的大小\r\n",
        "      return ILR_img\r\n",
        "\r\n",
        "\r\n",
        "def dataaug(img, size, flag):\r\n",
        "  if flag == 0:\r\n",
        "    img = cv2.flip(img, 0)  # 垂直翻转\r\n",
        "  elif flag == 1:\r\n",
        "    img = cv2.flip(img, 1)  # 水平翻转\r\n",
        "  elif flag == 2:\r\n",
        "    center = (size // 2, size // 2)\r\n",
        "    img = cv2.warpAffine(img, cv2.getRotationMatrix2D(center, 90, 1), (size, size))  # 原图旋转90度\r\n",
        "  elif flag == 3:\r\n",
        "    center = (size // 2, size // 2)\r\n",
        "    img = cv2.warpAffine(img, cv2.getRotationMatrix2D(center, 270, 1), (size, size))  # 原图旋转270度\r\n",
        "  return img\r\n",
        "\r\n",
        "\r\n",
        "def splitdata(img, size, Imgflag, aug_num=0):\r\n",
        "  imglist = []\r\n",
        "  length_num = img.shape[0]//size  # 长、宽分别可以分为多少块\r\n",
        "  width_num = img.shape[1]//size\r\n",
        "  for i in range(0, length_num):\r\n",
        "    for j in range(0, width_num):\r\n",
        "      if Imgflag == 0:\r\n",
        "        img_piece = img[(0+i*size):(size+i*size), (0+j*size):(size+j*size), :]  # 分块\r\n",
        "      else:\r\n",
        "        img_piece = img[(0+i*size):(size+i*size), (0+j*size):(size+j*size)]  # 分块\r\n",
        "      imglist.append(img_piece)\r\n",
        "      for k in range(0, aug_num):  # aug_num最大为4\r\n",
        "        imglist.append(dataaug(img_piece, size, k))\r\n",
        "  imglist = np.array(imglist)\r\n",
        "  return imglist\r\n",
        "\r\n",
        "\r\n",
        "def gettraindata(folder_name_list, size, scale, Rflag=0, Imgflag=0, sizeflag=0, aug_num=0):\r\n",
        "  firstflag = 0\r\n",
        "  ''' Imgflag=0，读取RGB图；Imgflag=1，读取灰度图；Imgflag=2，读取亮度图Y图层。默认读取RGB '''\r\n",
        "  if Imgflag == 0 or Imgflag == 2:\r\n",
        "    Imgform = cv2.IMREAD_COLOR\r\n",
        "  else:\r\n",
        "    Imgform = cv2.IMREAD_GRAYSCALE\r\n",
        "  for folder_name in folder_name_list:    \r\n",
        "    for img_name in tqdm(os.listdir(folder_name)):  # os.listdir返回当前文件夹下所有文件\r\n",
        "      file_name = folder_name + '/' + img_name\r\n",
        "      img = cv2.imread(file_name, Imgform)  # 读取文件\r\n",
        "      if Imgflag == 2:\r\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)  # 将RGB图像转换为YCrCb图像\r\n",
        "        img = img[:, :, 0]  # 只取Y图层\r\n",
        "      ''' Rflag=0，生成HR；Rflag=1，生成LR；Rflag=2，生成ILR '''\r\n",
        "      img = delcrust(img, scale, Imgflag, Rflag)  # 按照scale大小裁剪无法被整除的边缘\r\n",
        "      if (Rflag == 0 and sizeflag == 0) or (Rflag != 0 and sizeflag == 1):  # 对于HR默认是size*scale，其余默认是size。可以改变sizeflag来改变图像大小\r\n",
        "        splitsize = size*scale\r\n",
        "      else:\r\n",
        "        splitsize = size\r\n",
        "      sub_imglist = splitdata(img, splitsize, Imgflag, aug_num)\r\n",
        "      if firstflag == 0:\r\n",
        "        imglist = sub_imglist.copy()  # 第一张图要生成imglist\r\n",
        "        firstflag += 1\r\n",
        "      else:\r\n",
        "        imglist = np.append(imglist, sub_imglist, axis=0)  # 其余的只要叠加在第一维度（图像数）就可以\r\n",
        "  return imglist\r\n",
        "\r\n",
        "\r\n",
        "train_folders = ['/content/drive/MyDrive/Colaboratory/跨平台超分辨率/SR_train&test/SR_training_datasets/BSDS200_HR',\r\n",
        "          '/content/drive/MyDrive/Colaboratory/跨平台超分辨率/SR_train&test/SR_training_datasets/General100_HR',\r\n",
        "          '/content/drive/MyDrive/Colaboratory/跨平台超分辨率/SR_train&test/SR_training_datasets/T91_HR']\r\n",
        "val_folders = ['/content/drive/MyDrive/Colaboratory/跨平台超分辨率/SR_train&test/SR_testing_datasets/Set5_HR']\r\n",
        "y_train = gettraindata(train_folders, size, scale, Rflag=0, Imgflag=Imgflag, sizeflag=0, aug_num=aug_num)\r\n",
        "x_train = gettraindata(train_folders, size, scale, Rflag=1, Imgflag=Imgflag, sizeflag=0, aug_num=aug_num)\r\n",
        "y_val = getdata(val_folders, size, scale, Rflag=0, Imgflag=Imgflag, sizeflag=0)\r\n",
        "x_val = getdata(val_folders, size, scale, Rflag=1, Imgflag=Imgflag, sizeflag=0)\r\n",
        "if Imgflag != 0:  # 只有一个图层就需要单独增加层数这一维度\r\n",
        "  x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\r\n",
        "  y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], y_train.shape[2], 1))\r\n",
        "  x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], x_val.shape[2], 1))\r\n",
        "  y_val = np.reshape(y_val, (y_val.shape[0], y_val.shape[1], y_val.shape[2], 1))\r\n",
        "y_train = y_train/255.0  # 归一化\r\n",
        "x_train = x_train/255.0\r\n",
        "y_val = y_val/255.0\r\n",
        "x_val = x_val/255.0\r\n",
        "\r\n",
        "print('\\n')\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(x_val.shape)\r\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE0XvdwfmC8j"
      },
      "source": [
        "3.搭建神经网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAjEXPFjmGXA"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.initializers import he_normal\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "\r\n",
        "class Subpixel(Conv2D):\r\n",
        "    def __init__(self,\r\n",
        "                 filters,\r\n",
        "                 kernel_size,\r\n",
        "                 r,\r\n",
        "                 padding='valid',\r\n",
        "                 data_format=None,\r\n",
        "                 strides=(1,1),\r\n",
        "                 activation=None,\r\n",
        "                 use_bias=True,\r\n",
        "                 kernel_initializer='glorot_uniform',\r\n",
        "                 bias_initializer='zeros',\r\n",
        "                 kernel_regularizer=None,\r\n",
        "                 bias_regularizer=None,\r\n",
        "                 activity_regularizer=None,\r\n",
        "                 kernel_constraint=None,\r\n",
        "                 bias_constraint=None,\r\n",
        "                 **kwargs):\r\n",
        "        super(Subpixel, self).__init__(\r\n",
        "            filters=r*r*filters,\r\n",
        "            kernel_size=kernel_size,\r\n",
        "            strides=strides,\r\n",
        "            padding=padding,\r\n",
        "            data_format=data_format,\r\n",
        "            activation=activation,\r\n",
        "            use_bias=use_bias,\r\n",
        "            kernel_initializer=kernel_initializer,\r\n",
        "            bias_initializer=bias_initializer,\r\n",
        "            kernel_regularizer=kernel_regularizer,\r\n",
        "            bias_regularizer=bias_regularizer,\r\n",
        "            activity_regularizer=activity_regularizer,\r\n",
        "            kernel_constraint=kernel_constraint,\r\n",
        "            bias_constraint=bias_constraint,\r\n",
        "            **kwargs)\r\n",
        "        self.r = r\r\n",
        "\r\n",
        "    def _phase_shift(self, I):\r\n",
        "        r = self.r\r\n",
        "        bsize, a, b, c = I.get_shape().as_list()\r\n",
        "        bsize = K.shape(I)[0] # Handling Dimension(None) type for undefined batch dim\r\n",
        "        X = K.reshape(I, [bsize, a, b, int(c/(r*r)),r, r]) # bsize, a, b, c/(r*r), r, r\r\n",
        "        X = K.permute_dimensions(X, (0, 1, 2, 5, 4, 3))  # bsize, a, b, r, r, c/(r*r)\r\n",
        "        #Keras backend does not support tf.split, so in future versions this could be nicer\r\n",
        "        X = [X[:,i,:,:,:,:] for i in range(a)] # a, [bsize, b, r, r, c/(r*r)\r\n",
        "        X = K.concatenate(X, 2)  # bsize, b, a*r, r, c/(r*r)\r\n",
        "        X = [X[:,i,:,:,:] for i in range(b)] # b, [bsize, r, r, c/(r*r)\r\n",
        "        X = K.concatenate(X, 2)  # bsize, a*r, b*r, c/(r*r)\r\n",
        "        return X\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return self._phase_shift(super(Subpixel, self).call(inputs))\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        unshifted = super(Subpixel, self).compute_output_shape(input_shape)\r\n",
        "        return (unshifted[0], self.r*unshifted[1], self.r*unshifted[2], int(unshifted[3]/(self.r*self.r)))\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Conv2D, self).get_config()\r\n",
        "        config.pop('rank')\r\n",
        "        config.pop('dilation_rate')\r\n",
        "        config['filters']= int(config['filters'] / self.r*self.r)\r\n",
        "        config['r'] = self.r\r\n",
        "        return config\r\n",
        "\r\n",
        "\r\n",
        "class ResidualDenseBlock(Model):\r\n",
        "    def __init__(self, num_G):\r\n",
        "        super(ResidualDenseBlock, self).__init__()\r\n",
        "        self.num_G = num_G\r\n",
        "\r\n",
        "        self.c1 = Conv2D(filters=num_G, kernel_initializer=he_normal(), kernel_size=(3, 3), activation='relu',\r\n",
        "                         padding='same')\r\n",
        "        self.c2 = Conv2D(filters=num_G, kernel_initializer=he_normal(), kernel_size=(3, 3), activation='relu',\r\n",
        "                         padding='same')\r\n",
        "        self.c3 = Conv2D(filters=num_G, kernel_initializer=he_normal(), kernel_size=(3, 3), activation='relu',\r\n",
        "                         padding='same')\r\n",
        "        self.c4 = Conv2D(filters=num_G, kernel_initializer=he_normal(), kernel_size=(3, 3), activation='relu',\r\n",
        "                         padding='same')\r\n",
        "        self.c5 = Conv2D(filters=num_G, kernel_initializer=he_normal(), kernel_size=(3, 3), activation='relu',\r\n",
        "                         padding='same')\r\n",
        "        self.c6 = Conv2D(filters=num_G, kernel_initializer=he_normal(), kernel_size=(3, 3), activation='relu',\r\n",
        "                         padding='same')\r\n",
        "\r\n",
        "        self.c = Conv2D(filters=64, kernel_initializer=he_normal(), kernel_size=(1, 1), padding='same')\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        x1 = self.c1(inputs)\r\n",
        "        y1 = tf.concat([inputs, x1], 3)\r\n",
        "\r\n",
        "        x2 = self.c2(y1)\r\n",
        "        y2 = tf.concat([inputs, x1, x2], 3)\r\n",
        "\r\n",
        "        x3 = self.c3(y2)\r\n",
        "        y3 = tf.concat([inputs, x1, x2, x3], 3)\r\n",
        "\r\n",
        "        x4 = self.c4(y3)\r\n",
        "        y4 = tf.concat([inputs, x1, x2, x3, x4], 3)\r\n",
        "\r\n",
        "        x5 = self.c5(y4)\r\n",
        "        y5 = tf.concat([inputs, x1, x2, x3, x4, x5], 3)\r\n",
        "\r\n",
        "        x6 = self.c6(y5)\r\n",
        "        y6 = tf.concat([inputs, x1, x2, x3, x4, x5, x6], 3)\r\n",
        "\r\n",
        "        y = self.c(y6)\r\n",
        "        return y + inputs\r\n",
        "\r\n",
        "\r\n",
        "class RDN(Model):\r\n",
        "    def __init__(self, num_G, channels, scale):\r\n",
        "        super(RDN, self).__init__()\r\n",
        "        self.num_G = num_G\r\n",
        "        self.channels = channels\r\n",
        "        self.scale = scale\r\n",
        "\r\n",
        "        self.SFE1 = Conv2D(filters=64, kernel_initializer=he_normal(), kernel_size=(3, 3), padding='same')\r\n",
        "        self.SFE2 = Conv2D(filters=64, kernel_initializer=he_normal(), kernel_size=(3, 3), padding='same')\r\n",
        "\r\n",
        "        self.RDB1 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB2 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB3 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB4 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB5 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB6 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB7 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB8 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB9 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB10 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB11 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB12 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB13 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB14 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB15 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB16 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB17 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB18 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB19 = ResidualDenseBlock(self.num_G)\r\n",
        "        self.RDB20 = ResidualDenseBlock(self.num_G)\r\n",
        "\r\n",
        "        self.GFF1 = Conv2D(filters=64, kernel_initializer=he_normal(), kernel_size=(1, 1), padding='same')\r\n",
        "        self.GFF2 = Conv2D(filters=64, kernel_initializer=he_normal(), kernel_size=(3, 3), padding='same')\r\n",
        "\r\n",
        "        self.UP = Subpixel(64, (3,3), r=scale, padding='same',activation='relu')\r\n",
        "\r\n",
        "        self.c = Conv2D(filters=self.channels, kernel_initializer=he_normal(), kernel_size=(3, 3), padding='same')\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        sfe1 = self.SFE1(inputs)\r\n",
        "        sfe2 = self.SFE2(sfe1)\r\n",
        "\r\n",
        "        rdb1 = self.RDB1(sfe2)\r\n",
        "        rdb2 = self.RDB2(rdb1)\r\n",
        "        rdb3 = self.RDB3(rdb2)\r\n",
        "        rdb4 = self.RDB4(rdb3)\r\n",
        "        rdb5 = self.RDB5(rdb4)\r\n",
        "        rdb6 = self.RDB6(rdb5)\r\n",
        "        rdb7 = self.RDB7(rdb6)\r\n",
        "        rdb8 = self.RDB8(rdb7)\r\n",
        "        rdb9 = self.RDB9(rdb8)\r\n",
        "        rdb10 = self.RDB10(rdb9)\r\n",
        "        rdb11 = self.RDB11(rdb10)\r\n",
        "        rdb12 = self.RDB12(rdb11)\r\n",
        "        rdb13 = self.RDB13(rdb12)\r\n",
        "        rdb14 = self.RDB14(rdb13)\r\n",
        "        rdb15 = self.RDB15(rdb14)\r\n",
        "        rdb16 = self.RDB16(rdb15)\r\n",
        "        rdb17 = self.RDB17(rdb16)\r\n",
        "        rdb18 = self.RDB18(rdb17)\r\n",
        "        rdb19 = self.RDB19(rdb18)\r\n",
        "        rdb20 = self.RDB20(rdb19)\r\n",
        "        rdb = tf.concat([rdb1, rdb2, rdb3, rdb4, rdb5, rdb6, rdb7, rdb8, rdb9, rdb10,\r\n",
        "                rdb11, rdb12, rdb13, rdb14, rdb15, rdb16, rdb17, rdb18, rdb19, rdb20], 3)\r\n",
        "\r\n",
        "        gff1 = self.GFF1(rdb)\r\n",
        "        gff2 = self.GFF2(gff1)\r\n",
        "        dff = sfe1 + gff2\r\n",
        "\r\n",
        "        up = self.UP(dff)\r\n",
        "\r\n",
        "        y = self.c(up)\r\n",
        "        return y\r\n",
        "\r\n",
        "\r\n",
        "def L1_loss(y_true, y_pred):\r\n",
        "    return K.sum(K.abs(y_true - y_pred))\r\n",
        "\r\n",
        "def L1_mean_loss(y_true, y_pred):\r\n",
        "    return K.mean(K.abs(y_true - y_pred))\r\n",
        "\r\n",
        "\r\n",
        "model = RDN(num_G=num_G, channels=channels, scale=scale)\r\n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-8), loss=L1_loss)\r\n",
        "model.build((None, 32, 32, channels))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhZH5ZdImIEG"
      },
      "source": [
        "4.训练神经网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmlm0b4jmJfT"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "\r\n",
        "\r\n",
        "checkpoint_save_path = '/content/drive/MyDrive/Colaboratory/跨平台超分辨率/model_data/Y_CrCb/RDN.ckpt'\r\n",
        "best_ckpt = ModelCheckpoint(filepath=checkpoint_save_path, save_weights_only=True, save_best_only=True)\r\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.707, patience=2, verbose=1)\r\n",
        "callback_list = [best_ckpt, reduce_lr]\r\n",
        "model.fit(x_train, y_train, batch_size=16, epochs=100, validation_data=(x_val, y_val), callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSr5uwgmOFH"
      },
      "source": [
        "5.生成测试集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUrV1yT7mOfe"
      },
      "source": [
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "def delcrust(HR_img, scale, Imgflag=0, Rflag=0):  # 一样的，可以删除\r\n",
        "  HR_size = HR_img.shape\r\n",
        "  rem0 = HR_size[0]%scale\r\n",
        "  rem1 = HR_size[1]%scale\r\n",
        "  if Imgflag == 1:\r\n",
        "    HR_img = HR_img[:HR_size[0]-rem0, :HR_size[1]-rem1]  # 裁掉无法被scale整除的边缘，即为处理后的HR\r\n",
        "  else:\r\n",
        "    HR_img = HR_img[:HR_size[0]-rem0, :HR_size[1]-rem1, :]  # 裁掉无法被scale整除的边缘，即为处理后的HR\r\n",
        "  ''' Rflag=0，生成HR；Rflag=1，生成LR；Rflag=2，生成ILR。默认生成HR '''\r\n",
        "  if Rflag == 0:\r\n",
        "    return HR_img\r\n",
        "  if Rflag == 1 or Rflag == 2:\r\n",
        "    HR_size = HR_img.shape\r\n",
        "    HR_size = (HR_size[1], HR_size[0])\r\n",
        "    LR_size = (int(HR_size[0]/scale), int(HR_size[1]/scale))\r\n",
        "    LR_img = cv2.resize(HR_img, LR_size, interpolation = cv2.INTER_LINEAR)  # 边长缩小scale倍\r\n",
        "    if Rflag == 1:\r\n",
        "      return LR_img\r\n",
        "    else:\r\n",
        "      ILR_img = cv2.resize(LR_img, HR_size, interpolation = cv2.INTER_LINEAR)  # 再插值恢复成HR的大小\r\n",
        "      return ILR_img\r\n",
        "\r\n",
        "\r\n",
        "def splitdata(img, size, Imgflag=0):  # 补上aug_num=0即可\r\n",
        "  imglist = []\r\n",
        "  length_num = img.shape[0]//size\r\n",
        "  width_num = img.shape[1]//size\r\n",
        "  for i in range(0, length_num):\r\n",
        "    for j in range(0, width_num):\r\n",
        "      if Imgflag == 0:\r\n",
        "        img_piece = img[(0+i*size):(size+i*size), (0+j*size):(size+j*size), :]  # 分块\r\n",
        "      else:\r\n",
        "        img_piece = img[(0+i*size):(size+i*size), (0+j*size):(size+j*size)]  # 分块\r\n",
        "      imglist.append(img_piece)\r\n",
        "  imglist = np.array(imglist)\r\n",
        "  return imglist\r\n",
        "\r\n",
        "\r\n",
        "def gettestdata(file_name, size, scale, Rflag=0, Imgflag=0, sizeflag=0):\r\n",
        "  ''' Imgflag=0，读取灰度图；Imgflag=1，读取RGB图。默认读取RGB '''\r\n",
        "  if Imgflag == 0 or Imgflag == 2:\r\n",
        "    Imgform = cv2.IMREAD_COLOR\r\n",
        "  else:\r\n",
        "    Imgform = cv2.IMREAD_GRAYSCALE\r\n",
        "  img = cv2.imread(file_name, Imgform)  # 读取文件\r\n",
        "  if Imgflag == 2:\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)  # 将RGB图像转换为YCrCb图像\r\n",
        "  ''' Rflag=0，生成HR；Rflag=1，生成LR；Rflag=2，生成ILR '''\r\n",
        "  img = delcrust(img, scale, Imgflag, Rflag)  # 按照scale大小裁剪无法被整除的边缘\r\n",
        "  if Imgflag == 2:  # 亮度图只取Y图层进行运算，但要保留剩下的两个图层\r\n",
        "    img_res = img[:, :, -2:]  # 后两个图层\r\n",
        "    img = img[:, :, 0]  # 只取Y图层\r\n",
        "  else:\r\n",
        "    img_res = None\r\n",
        "  if (Rflag == 0 and sizeflag == 0) or (Rflag != 0 and sizeflag == 1):  # 对于HR默认是size*scale，其余默认是size。可以改变sizeflag来改变图像大小\r\n",
        "    splitsize = size*scale\r\n",
        "  else:\r\n",
        "    splitsize = size\r\n",
        "  imglist = splitdata(img, splitsize, Imgflag)\r\n",
        "  return imglist, img, img_res\r\n",
        "\r\n",
        "\r\n",
        "file_name = '/content/drive/MyDrive/Colaboratory/跨平台超分辨率/SR_train&test/SR_testing_datasets/Set5_HR/butterfly.png'\r\n",
        "HR_test, HR_img, HR_res = gettestdata(file_name, size, scale, Rflag=0, Imgflag=Imgflag, sizeflag=0)\r\n",
        "LR_test, LR_img, LR_res = gettestdata(file_name, size, scale, Rflag=1, Imgflag=Imgflag, sizeflag=0)\r\n",
        "y_test = HR_test/255.0\r\n",
        "x_test = LR_test/255.0\r\n",
        "if Imgflag != 0:\r\n",
        "  x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\r\n",
        "  y_test = np.reshape(y_test, (y_test.shape[0], y_test.shape[1], y_test.shape[2], 1))\r\n",
        "\r\n",
        "print(HR_img.shape, LR_img.shape)\r\n",
        "if Imgflag == 2:\r\n",
        "  print(HR_res.shape, LR_res.shape)\r\n",
        "print(y_test.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMv_Hx-JmQCR"
      },
      "source": [
        "6.使用测试集进行评估"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBunwcFdmRrb"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/Colaboratory/跨平台超分辨率/model_data/Y_CrCb/1/RDN.ckpt')\r\n",
        "model.evaluate(x_test, y_test, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAA0r8rCmS-p"
      },
      "source": [
        "7.拼接并图示测试图片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hneNhB7EmUmy"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import cv2\r\n",
        "import math\r\n",
        "\r\n",
        "\r\n",
        "def imgappend(img_pieces, length_num, width_num):\r\n",
        "  num = 0\r\n",
        "  for i in range(0, length_num):\r\n",
        "    for j in range(0, width_num):\r\n",
        "      if j == 0:\r\n",
        "        width_array = img_pieces[num, :, :]\r\n",
        "      else:\r\n",
        "        width_array = np.append(width_array, img_pieces[num, :, :, :], axis=1)  # 横向拼接\r\n",
        "      num += 1\r\n",
        "    if i == 0:\r\n",
        "      length_array = width_array.copy()\r\n",
        "    else:\r\n",
        "      length_array = np.append(length_array, width_array, axis=0)  # 纵向拼接\r\n",
        "  return length_array\r\n",
        "\r\n",
        "\r\n",
        "def getYimg(ILR_img, pred_img, HR_img, LR_res, HR_res):\r\n",
        "  HR_img = np.reshape(HR_img, (HR_img.shape[0], HR_img.shape[1], 1))\r\n",
        "  ILR_img = np.reshape(ILR_img, (ILR_img.shape[0], ILR_img.shape[1], 1))\r\n",
        "  pred_img = np.reshape(pred_img, (ILR_img.shape[0], ILR_img.shape[1], 1))\r\n",
        "  ILR_res = cv2.resize(LR_res, (LR_res.shape[1]*scale, LR_res.shape[0]*scale), interpolation = cv2.INTER_LINEAR)\r\n",
        "  HR_res = HR_res[:HR_img.shape[0], :HR_img.shape[1], :]\r\n",
        "  ILR_res = ILR_res[:ILR_img.shape[0], :ILR_img.shape[1], :]\r\n",
        "  HR_img = np.append(HR_img, HR_res, axis=2)\r\n",
        "  ILR_img = np.append(ILR_img, ILR_res, axis=2)\r\n",
        "  pred_img = np.append(pred_img, ILR_res, axis=2)\r\n",
        "  ILR_img = cv2.cvtColor(ILR_img, cv2.COLOR_YCR_CB2BGR)\r\n",
        "  pred_img = cv2.cvtColor(pred_img, cv2.COLOR_YCR_CB2BGR)\r\n",
        "  HR_img = cv2.cvtColor(HR_img, cv2.COLOR_YCR_CB2BGR)\r\n",
        "  return ILR_img, pred_img, HR_img\r\n",
        "\r\n",
        "\r\n",
        "def psnr(y_true, y_pred):\r\n",
        "  y_true = cv2.cvtColor(y_true, cv2.COLOR_BGR2YCR_CB)\r\n",
        "  y_pred = cv2.cvtColor(y_pred, cv2.COLOR_BGR2YCR_CB)\r\n",
        "  y_true = y_true[:, :, 0]\r\n",
        "  y_pred = y_pred[:, :, 0]\r\n",
        "  mse = np.mean((y_true/1.0 - y_pred/1.0) ** 2 )\r\n",
        "  return 10 * math.log10(255.0**2/mse)\r\n",
        "\r\n",
        "\r\n",
        "y_pred = model.predict(x_test)\r\n",
        "\r\n",
        "length_num = HR_img.shape[0] // (size * scale)\r\n",
        "width_num = HR_img.shape[1] // (size * scale)\r\n",
        "pred_img = imgappend(y_pred, length_num, width_num)\r\n",
        "pred_img = (pred_img * 255).astype(np.uint8)\r\n",
        "if Imgflag == 0:\r\n",
        "  HR_img = HR_img[:pred_img.shape[0], :pred_img.shape[1], :pred_img.shape[2]]\r\n",
        "  LR_img = LR_img[:pred_img.shape[0]//scale, :pred_img.shape[1]//scale, :pred_img.shape[2]]\r\n",
        "else:\r\n",
        "  HR_img = HR_img[:pred_img.shape[0], :pred_img.shape[1]]\r\n",
        "  LR_img = LR_img[:pred_img.shape[0]//scale, :pred_img.shape[1]//scale]\r\n",
        "  pred_img = np.reshape(pred_img, (pred_img.shape[0], pred_img.shape[1]))\r\n",
        "ILR_img = cv2.resize(LR_img, (LR_img.shape[1]*scale, LR_img.shape[0]*scale), interpolation = cv2.INTER_LINEAR)\r\n",
        "if Imgflag == 2:\r\n",
        "  ILR_img, pred_img, HR_img = getYimg(ILR_img, pred_img, HR_img, LR_res, HR_res)\r\n",
        "\r\n",
        "\r\n",
        "if Imgflag != 1:  # 灰度图无法计算psnr，也不需要调换图层顺序\r\n",
        "  cmap = None\r\n",
        "  print('PSNR between ILR and HR:', psnr(HR_img, ILR_img))\r\n",
        "  print('PSNR between output and HR:', psnr(HR_img, pred_img), '\\n')\r\n",
        "\r\n",
        "  b,g,r = cv2.split(pred_img)\r\n",
        "  pred_img = cv2.merge([r,g,b])\r\n",
        "  b,g,r = cv2.split(HR_img)\r\n",
        "  HR_img = cv2.merge([r,g,b])\r\n",
        "  b,g,r = cv2.split(ILR_img)\r\n",
        "  ILR_img = cv2.merge([r,g,b])\r\n",
        "else:\r\n",
        "  cmap = plt.cm.gray\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 15))\r\n",
        "\r\n",
        "plt.subplot(1,3,1)\r\n",
        "plt.imshow(ILR_img, cmap)\r\n",
        "plt.title(\"ILR\")\r\n",
        "\r\n",
        "plt.subplot(1,3,2)\r\n",
        "plt.imshow(pred_img, cmap)\r\n",
        "plt.title(\"prediction\")\r\n",
        "\r\n",
        "plt.subplot(1,3,3)\r\n",
        "plt.imshow(HR_img, cmap)\r\n",
        "plt.title(\"HR\")\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}